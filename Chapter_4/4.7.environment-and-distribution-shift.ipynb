{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9dd4d342",
   "metadata": {
    "origin_pos": 0
   },
   "source": [
    "# Environment and Distribution Shift\n",
    "\n",
    "## 1. Distribution Shift\n",
    "A **distribution shift** occurs when the data distribution changes between training and testing (or deployment) phases. Formally, it means:\n",
    "\n",
    "- Training data: $P_{train}(x, y)$\n",
    "- Test data: $P_{test}(x, y)$\n",
    "\n",
    "If $P_{train}(x, y) \\neq P_{test}(x, y)$, then the model is facing a distribution shift.\n",
    "\n",
    "Types of distribution shifts include:\n",
    "- **Covariate shift**: $P_{train}(x) \\neq P_{test}(x)$ but $P(y|x)$ stays the same.\n",
    "- **Label shift**: $P_{train}(y) \\neq P_{test}(y)$ but $ P(x|y)$ stays the same.\n",
    "- **Concept shift**: $ P(y|x)$ itself changes — this is the most challenging.\n",
    "\n",
    "### 2. Environment Shift\n",
    "This is a broader concept that often refers to changes in the **underlying causal mechanisms** or data-generating processes, often across **domains**, **tasks**, or **real-world conditions**. It overlaps with ideas from:\n",
    "- **Out-of-distribution (OOD) generalization**\n",
    "- **Domain adaptation**\n",
    "- **Causal inference**\n",
    "\n",
    "In reinforcement learning or decision-making problems, an \"environment\" refers to the system with which an agent interacts. A shift in the environment (e.g., policy deployment in the real world vs. simulation) can degrade performance if the agent overfits to the training environment.\n",
    "\n",
    "## 3. Importance of Understanding Env./Dist. Shifts\n",
    "\n",
    "- Self-driving cars trained in sunny California may struggle in snowy Norway.\n",
    "- A disease classifier trained on hospital A’s data may misdiagnose patients in hospital B.\n",
    "\n",
    "## 4. How to Handle Shifts\n",
    "\n",
    "- **Domain adaptation**: Adapts models trained in one domain to perform well in another.\n",
    "- **Test-time adaptation**: Adjusts the model on the fly during deployment.\n",
    "- **Data augmentation and diversity**: Enriches training data to cover multiple modes or environments.\n",
    "- **Causal models**: Learn stable causal relationships that are less sensitive to distribution shifts.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c5309b7",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "required_libs": []
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
