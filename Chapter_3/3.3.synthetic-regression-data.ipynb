{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.3. Synthetic Regression Data\n",
    "\n",
    "$ \\newcommand{\\mb}{\\mathbf}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import torch\n",
    "from d2l import torch as d2l"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.3.1. Generating the Dataset\n",
    "\n",
    "We will generate a synthetic dataset $\\mb{X}$ and corresponding labels $\\mb{y}$ from the following linear regression model:\n",
    "\n",
    "$\\mb{y} = \\mb{X} \\mb{w} + \\mb{b} + \\mb{\\epsilon}$\n",
    "\n",
    "where $\\mb{X} \\in \\mathbb{R}^{n \\times d}$, $\\mb{w} \\in \\mathbb{R}^{d}$, $\\mb{b} \\in \\mathbb{R}$, and $\\mb{\\epsilon} \\in \\mathbb{R}^{n}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SyntheticRegressionData(d2l.DataModule):\n",
    "    \"\"\"Synthetic data for linear regression.\"\"\"\n",
    "    def __init__(self, w, b, noise=0.01, num_train=1000, num_val=1000, batch_size=32):\n",
    "        super().__init__()\n",
    "        self.save_hyperparameters()\n",
    "        n = num_train + num_val\n",
    "        self.X = torch.randn(n, len(w))\n",
    "        noise = torch.randn(n, 1) * noise\n",
    "        self.y = torch.matmul(self.X, w.reshape((-1, 1))) + b + noise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As an example, let's set the true parameter as\n",
    "$\\mb{w} = [2,-3.4]^T$ and $b = 4.2$.\n",
    "\n",
    "Our job is to estimate $\\mb{w}$ and $b$ from the dataset $\\mb{X}$ and $\\mb{y}$, and compare the estimated values with the true values.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = SyntheticRegressionData(\n",
    "    w=torch.tensor([2, -3.4]), \n",
    "    b=4.2, \n",
    "    num_train=1000,\n",
    "    num_val=1000,\n",
    "    batch_size=32 \n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Row 0] features: tensor([-1.3575, -0.6905]), label: tensor([3.8496])\n",
      "[Row 1] features: tensor([ 2.5720, -0.1056]), label: tensor([9.7022])\n",
      "[Row 2] features: tensor([ 0.0956, -0.9048]), label: tensor([7.4566])\n",
      "[Row 3] features: tensor([1.6608, 0.1641]), label: tensor([6.9709])\n"
     ]
    }
   ],
   "source": [
    "# print first 4 rows\n",
    "for i in range(4):\n",
    "    print(f'[Row {i}] features: {data.X[i]}, label: {data.y[i]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.3.2. Reading the Dataset\n",
    "\n",
    "- SyntheticRegressionData inherits from d2l.DataModule class.\n",
    "- We need to implement `get_dataloader` method to return the dataloader for the synthetic regression dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "@d2l.add_to_class(SyntheticRegressionData)\n",
    "def get_dataloader(self,train):\n",
    "    if train:\n",
    "        indices = list(range(0, self.num_train))\n",
    "        random.shuffle(indices)\n",
    "    else:\n",
    "        indices = list(range(self.num_train, self.num_train + self.num_val))\n",
    "    \n",
    "    for i in range(0, len(indices), self.batch_size):\n",
    "        batch_indices = torch.tensor(indices[i: i + self.batch_size])\n",
    "        yield (self.X[batch_indices], self.y[batch_indices])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X.shape: torch.Size([32, 2])\n",
      "y.shape: torch.Size([32, 1])\n"
     ]
    }
   ],
   "source": [
    "# First batch of training data (batch size 32)\n",
    "X, y = next(iter(data.get_dataloader(train=True)))\n",
    "print (f'X.shape: {X.shape}\\ny.shape: {y.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The above example illustrates usefulness of object-oriented programming.\n",
    "- We can define a generic class `DataModule` that can be inherited by other classes to implement specific functionalities.\n",
    "- This way, we can reuse the code and make it more modular.\n",
    "\n",
    "But, the above implementation is inefficient in many ways. For example, we load all the data in memory and that we perform lots of random memory access.\n",
    "\n",
    "In deep learning frameworks (e.g. pytorch), optimized built-in data loaders are available that can handle large datasets efficiently."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.3.3. Concise Implementation of the Data Loader "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "d2l.DataModule implements `get_tensorloader` method that takes tensors (features, target) and returns the pytorch dataloader.\n",
    "\n",
    "```python\n",
    "class DataModule(d2l.HyperParameters):\n",
    "    ...\n",
    "\n",
    "    def get_tensorloader(self, tensors, train, indices=slice(0, None)):\n",
    "        \"\"\"Defined in :numref:`sec_synthetic-regression-data`\"\"\"\n",
    "        tensors = tuple(a[indices] for a in tensors)\n",
    "        dataset = torch.utils.data.TensorDataset(*tensors)\n",
    "        return torch.utils.data.DataLoader(dataset, self.batch_size,\n",
    "                                           shuffle=train)\n",
    "\n",
    "    ...\n",
    "```\n",
    "\n",
    "We can use get_tensorloader method to get the dataloader for the synthetic regression dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "@d2l.add_to_class(SyntheticRegressionData)\n",
    "def get_dataloader(self, train):\n",
    "    # if train is True, return the first num_train data points\n",
    "    # if train is False, return the rest of the data points\n",
    "    i = slice(0, self.num_train) if train else slice(self.num_train, None)\n",
    "    return self.get_tensorloader((self.X, self.y), train, i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The new data loader behaves just like the previous one, except that it is more efficient and has some added functionality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X shape: torch.Size([32, 2]) \n",
      "y shape: torch.Size([32, 1])\n",
      "len(data.train_dataloader()): 32\n"
     ]
    }
   ],
   "source": [
    "X, y = next(iter(data.train_dataloader()))\n",
    "print('X shape:', X.shape, '\\ny shape:', y.shape)\n",
    "print(f'len(data.train_dataloader()): {len(data.train_dataloader())}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "d2l",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
